{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:45:07.749510Z",
     "start_time": "2024-03-11T19:45:05.663691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 different classes: Electronic, Experimental, Folk, Hip-Hop, Instrumental, International, Pop or Rock.\n",
      "objective 1: construct a classifier which, based on the features of a song, predicts its genre\n",
      "objective 2: estimate its generalisation error under the 0â€“1 loss.\n",
      "Features are real-valued, correspond to summary statistics (mean, sd, skewness, kurtosis, median, min, max) of \n",
      "time series of various music features, such as the chromagram or the Mel-frequency cepstrum.\n",
      "Feature description: \n",
      "\n",
      "Feature description: \n",
      "chroma_cens: Chroma Energy Normalized (CENS, 12 chroma) - 84 features\n",
      "chroma_cqt: Constant-Q chromagram (12 chroma) - 84 features\n",
      "chroma_stft: Chromagram (12 chroma) - 84 features\n",
      "mfcc: Mel-frequency cepstrum (20 coefficients) - 140 features\n",
      "rmse: Root-mean-square - 7 features\n",
      "spectral_bandwidth: Spectral bandwidth - 7 features\n",
      "spectral_centroid: Spectral centroid - 7 features\n",
      "spectral_contrast: Spectral contrast (7 frequency bands) - 49 features\n",
      "spectral_rolloff: Roll-off frequency - 7 features\n",
      "tonnetz: Tonal centroid features (6 features) - 42 features\n",
      "zcr: Zero-crossing rate - 7 features\n",
      "x_train: 6000 rows on 518 columns\n",
      "Objects loaded: x_train, x_test, y_train as pd dataframes, x_train_np, x_test_np, y_train_np as NP arrays\n",
      "function generate_submission_csv(genre_predictions, filename='submission.csv') available\n"
     ]
    }
   ],
   "source": [
    "%run 'Setup.py'"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import optuna"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T20:25:52.563186Z",
     "start_time": "2024-03-11T20:25:52.148272Z"
    }
   },
   "id": "3e20111fe35c3791",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 518) (4800,)\n",
      "(1200, 518) (1200,)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(x, y):\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(x)\n",
    "    return train_test_split(x_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = preprocess_data(x_train_np, y_train_np)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T20:17:37.221215Z",
     "start_time": "2024-03-11T20:17:37.179862Z"
    }
   },
   "id": "ddbc5e03ee794951",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "# Initialize the encoder\n",
    "label_encoder = LabelEncoder()\n",
    "# Flatten\n",
    "\n",
    "# Fit the encoder on the training labels\n",
    "y_train_encoded = label_encoder.fit_transform(Y_train.ravel())\n",
    "\n",
    "# Transform the test labels using the same encoder\n",
    "y_test_encoded = label_encoder.transform(Y_test)\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.int64)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.int64)\n",
    "# Create TensorDatasets and DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T20:17:37.960867Z",
     "start_time": "2024-03-11T20:17:37.950280Z"
    }
   },
   "id": "298622d1c81a2405",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# \n",
    "# class MusicGenreCNN(nn.Module):\n",
    "#     def __init__(self, n_input_channels=1, n_filters=64, n_classes=8):\n",
    "#         super(MusicGenreCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(n_input_channels, n_filters, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool1d(2)\n",
    "#         self.dropout1 = nn.Dropout(0.2)\n",
    "#         \n",
    "#         self.conv2 = nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=1)\n",
    "#         # Pooling same as above, so no need to redefine\n",
    "#         self.dropout2 = nn.Dropout(0.2)\n",
    "#         \n",
    "#         self.conv3 = nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=1)\n",
    "#         # Pooling and dropout same as above\n",
    "#         self.dropout3 = nn.Dropout(0.2)\n",
    "#         \n",
    "#         self.conv4 = nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=1)\n",
    "#         self.dropout4 = nn.Dropout(0.3)\n",
    "#         \n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.fc = nn.Linear(n_filters * (518 // 16), n_classes)  # Adjusted for 4 max-poolings halving the dimension each time\n",
    "# \n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.dropout1(x)\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.pool(F.relu(self.conv3(x)))\n",
    "#         x = self.dropout3(x)\n",
    "#         x = self.pool(F.relu(self.conv4(x)))\n",
    "#         x = self.dropout4(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "# \n",
    "# # Assuming your input data X_train_tensor is correctly shaped\n",
    "# # Initialize the model\n",
    "# model = MusicGenreCNN(n_input_channels=1, n_filters=64, n_classes=8)\n",
    "# class MusicGenreCNN(nn.Module):\n",
    "#     def __init__(self, n_input_channels=1, n_filters=64, n_classes=8):\n",
    "#         super(MusicGenreCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(n_input_channels, n_filters, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool1d(2)\n",
    "#         self.dropout1 = nn.Dropout(0.3)\n",
    "#         \n",
    "#         self.conv2 = nn.Conv1d(n_filters, n_filters * 2, kernel_size=3, padding=1)\n",
    "#         self.dropout2 = nn.Dropout(0.3)\n",
    "#         \n",
    "#         self.conv3 = nn.Conv1d(n_filters * 2, n_filters * 4, kernel_size=3, padding=1)\n",
    "#         self.dropout3 = nn.Dropout(0.3)\n",
    "#         \n",
    "#         # New additional layers\n",
    "#         self.conv4 = nn.Conv1d(n_filters * 4, n_filters * 8, kernel_size=3, padding=1)\n",
    "#         self.dropout4 = nn.Dropout(0.3)\n",
    "#         \n",
    "#         self.conv5 = nn.Conv1d(n_filters * 8, n_filters * 16, kernel_size=3, padding=1)\n",
    "#         self.dropout5 = nn.Dropout(0.3)\n",
    "#         \n",
    "#         # Adjusted fully connected layer to match new output size\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         # This fc layer size might need adjustment based on the output size of the last conv layer\n",
    "#         self.fc = nn.Linear(n_filters * 16 * (518 // 32), n_classes)\n",
    "# \n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.dropout1(x)\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.pool(F.relu(self.conv3(x)))\n",
    "#         x = self.dropout3(x)\n",
    "#         x = self.pool(F.relu(self.conv4(x)))\n",
    "#         x = self.dropout4(x)\n",
    "#         x = self.pool(F.relu(self.conv5(x)))\n",
    "#         x = self.dropout5(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "# Adaptive model for optuna study\n",
    "# class MusicGenreCNN(nn.Module):\n",
    "#     def __init__(self, n_input_channels=1, n_filters=64, n_classes=8, dropout_rate1=0.3, dropout_rate2=0.3, dropout_rate3=0.3, dropout_rate4=0.3, dropout_rate5=0.3):\n",
    "#         super(MusicGenreCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(n_input_channels, n_filters, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool1d(2)\n",
    "#         self.dropout1 = nn.Dropout(dropout_rate1)\n",
    "#         \n",
    "#         self.conv2 = nn.Conv1d(n_filters, n_filters * 2, kernel_size=3, padding=1)\n",
    "#         self.dropout2 = nn.Dropout(dropout_rate2)\n",
    "#         \n",
    "#         self.conv3 = nn.Conv1d(n_filters * 2, n_filters * 4, kernel_size=3, padding=1)\n",
    "#         self.dropout3 = nn.Dropout(dropout_rate3)\n",
    "#         \n",
    "#         # New additional layers\n",
    "#         self.conv4 = nn.Conv1d(n_filters * 4, n_filters * 8, kernel_size=3, padding=1)\n",
    "#         self.dropout4 = nn.Dropout(dropout_rate4)\n",
    "#         \n",
    "#         self.conv5 = nn.Conv1d(n_filters * 8, n_filters * 16, kernel_size=3, padding=1)\n",
    "#         self.dropout5 = nn.Dropout(dropout_rate5)\n",
    "#         \n",
    "#         # Adjusted fully connected layer to match new output size\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         # The fc layer size might need adjustment based on the output size of the last conv layer\n",
    "#         self.fc = nn.Linear(n_filters * 16 * (518 // 32), n_classes)\n",
    "# \n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.dropout1(x)\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.pool(F.relu(self.conv3(x)))\n",
    "#         x = self.dropout3(x)\n",
    "#         x = self.pool(F.relu(self.conv4(x)))\n",
    "#         x = self.dropout4(x)\n",
    "#         x = self.pool(F.relu(self.conv5(x)))\n",
    "#         x = self.dropout5(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "# class MusicGenreCNN(nn.Module):\n",
    "#     def __init__(self, n_input_channels=1, n_filters=64, n_classes=8, dropout_rates=None):\n",
    "#         super(MusicGenreCNN, self).__init__()\n",
    "#         if dropout_rates is None:\n",
    "#             dropout_rates = [0.2, 0.2, 0.2, 0.3]  # Default dropout rates\n",
    "#         assert len(dropout_rates) == 4, \"There must be 4 dropout rates\"\n",
    "# \n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Conv1d(n_input_channels, n_filters, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(2),\n",
    "#             nn.Dropout(dropout_rates[0]),\n",
    "#             \n",
    "#             nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(2),\n",
    "#             nn.Dropout(dropout_rates[1]),\n",
    "#             \n",
    "#             nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(2),\n",
    "#             nn.Dropout(dropout_rates[2]),\n",
    "#             \n",
    "#             nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(2),\n",
    "#             nn.Dropout(dropout_rates[3]),\n",
    "#         )\n",
    "#         \n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Flatten(),\n",
    "#             # Assuming your feature size needs adjusting based on the conv/pool operations\n",
    "#             nn.Linear(n_filters * (518 // 16), n_classes)  # Adjust the input features accordingly\n",
    "#         )\n",
    "# \n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T21:29:46.941720Z",
     "start_time": "2024-03-11T21:29:46.932150Z"
    }
   },
   "id": "553de499f33dba0e",
   "execution_count": 136
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MusicGenreCNN(nn.Module):\n",
    "    def __init__(self, n_input_channels=1, n_filters=64, n_classes=8):\n",
    "        super(MusicGenreCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input_channels, n_filters, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.dropout1 = nn.Dropout(0.6)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.dropout3 = nn.Dropout(0.6)\n",
    "\n",
    "        self.conv4 = nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AvgPool1d(2)\n",
    "        self.dropout4 = nn.Dropout(0.6)\n",
    "        \n",
    "        self.conv5 = nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.dropout5 = nn.Dropout(0.4)\n",
    "\n",
    "\n",
    "        # Adjusted fully connected layer to match new output size\n",
    "        self.flatten = nn.Flatten()\n",
    "        # # This fc layer size might need adjustment based on the output size of the last conv layer\n",
    "        # # self.fc = nn.Linear(n_filters * 16 * (518 // 32), n_classes)\n",
    "        self.fc = nn.Linear(n_filters * (518 // 8), n_classes)\n",
    "        # self.num_flat_features = None\n",
    "        # self.fc = None  # Will be defined dynamically\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        # x = self.pool(F.relu(self.conv4(x)))\n",
    "        # x = self.dropout4(x)\n",
    "        # x = self.pool(F.relu(self.conv5(x)))\n",
    "        # x = self.dropout5(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T21:54:35.175373Z",
     "start_time": "2024-03-11T21:54:35.168822Z"
    }
   },
   "id": "6b93f9e730b3bca1",
   "execution_count": 244
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.9083379199427943\n",
      "Epoch 2, Loss: 1.6020326229833788\n",
      "Epoch 3, Loss: 1.4975919838874572\n",
      "Epoch 4, Loss: 1.410888760320602\n",
      "Epoch 5, Loss: 1.3849179283265145\n",
      "Epoch 6, Loss: 1.3333338768251481\n",
      "Epoch 7, Loss: 1.315898560708569\n",
      "Epoch 8, Loss: 1.2686718279315579\n",
      "Epoch 9, Loss: 1.2503935194784594\n",
      "Epoch 10, Loss: 1.2151715101734284\n",
      "Epoch 11, Loss: 1.206392203607867\n",
      "Epoch 12, Loss: 1.1944377999151907\n",
      "Epoch 13, Loss: 1.1557399361364302\n",
      "Epoch 14, Loss: 1.1496552248154916\n",
      "Epoch 15, Loss: 1.1076102545184474\n",
      "Epoch 16, Loss: 1.1144411083190673\n",
      "Epoch 17, Loss: 1.102763347087368\n",
      "Epoch 18, Loss: 1.1068940950978188\n",
      "Epoch 19, Loss: 1.046163034054541\n",
      "Epoch 20, Loss: 1.0636514136868138\n",
      "Epoch 21, Loss: 1.0502610841105062\n",
      "Epoch 22, Loss: 1.0107255578041077\n",
      "Epoch 23, Loss: 1.0113064473675144\n",
      "Epoch 24, Loss: 0.9926392570618661\n",
      "Epoch 25, Loss: 1.0119221056661298\n",
      "Epoch 26, Loss: 0.9878244630752071\n",
      "Epoch 27, Loss: 0.9609614764490435\n",
      "Epoch 28, Loss: 0.949836173365193\n",
      "Epoch 29, Loss: 0.9312332522484564\n",
      "Epoch 30, Loss: 0.9411931057130137\n"
     ]
    }
   ],
   "source": [
    "# Set the device based on MPS availability\n",
    "model = MusicGenreCNN(n_input_channels=1, n_filters=128, n_classes=8)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to the selected device\n",
    "model.to(device)\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "weight_decay = 0.01  # Adjust the weight decay coefficient as needed\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=weight_decay)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# scheduler = StepLR(optimizer, step_size=60, gamma=0.15)\n",
    "epochs = 30  # Number of training epochs\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to the device\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()  # Adjust the learning rate\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T22:06:01.653114Z",
     "start_time": "2024-03-11T22:05:51.700188Z"
    }
   },
   "id": "82e8f2f47e3ca709",
   "execution_count": 264
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test set: 0.52\n",
      "Accuracy of the model on the training set: 0.78\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No need to track gradients\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy of the model on the test set: {accuracy:.2f}')\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No need to track gradients\n",
    "    for inputs, labels in train_loader:  # Use your training data loader\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "train_accuracy = correct / total\n",
    "print(f'Accuracy of the model on the training set: {train_accuracy:.2f}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T22:06:03.756934Z",
     "start_time": "2024-03-11T22:06:03.326727Z"
    }
   },
   "id": "cf96c51d8edacd54",
   "execution_count": 265
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume X_train_tensor, y_train_tensor are your full training dataset and labels\n",
    "# Splitting the training data to create a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_tensor.numpy(), y_train_tensor.numpy(), test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.int64)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.int64)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    # optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'RMSprop', 'SGD'])\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    dropout_rate1 = trial.suggest_float('dropout_rate1', 0.1, 0.5)\n",
    "    dropout_rate2 = trial.suggest_float('dropout_rate2', 0.1, 0.5)\n",
    "    dropout_rate3 = trial.suggest_float('dropout_rate3', 0.1, 0.5)\n",
    "    dropout_rate4 = trial.suggest_float('dropout_rate4', 0.1, 0.5)\n",
    "    # dropout_rate5 = trial.suggest_float('dropout_rate5', 0.1, 0.5)\n",
    "    \n",
    "    # Model setup with the suggested dropout rates\n",
    "    model = MusicGenreCNN(n_input_channels=1, n_filters=128, n_classes=8, dropout_rates = [dropout_rate1, dropout_rate2, dropout_rate3, dropout_rate4]).to(device)\n",
    "    \n",
    "    \n",
    "    # optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    # Training loop\n",
    "    for epoch in range(20):  # Using a smaller number of epochs for quicker trials\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                val_loss += F.cross_entropy(output, target, reduction='sum').item()  # Sum up batch loss\n",
    "                pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        accuracy = correct / len(val_loader.dataset)\n",
    "        \n",
    "    return accuracy  # or return -val_loss to minimize loss\n",
    "\n",
    "# Note: Ensure that your MusicGenreCNN class is adjusted to accept dropout_rate1 and dropout_rate2 as arguments\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T20:49:53.656505Z",
     "start_time": "2024-03-11T20:49:53.646243Z"
    }
   },
   "id": "cbc98ebbf7ab8fa9",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-11 20:49:54,378] A new study created in memory with name: CNN\n",
      "/var/folders/lq/x2t80c813gsbg58jgjy302hc0000gn/T/ipykernel_62643/4255941997.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "[I 2024-03-11 20:50:03,685] Trial 0 finished with value: 0.47560975609756095 and parameters: {'lr': 0.0003040238461502885, 'dropout_rate1': 0.4158264601071505, 'dropout_rate2': 0.3957060389119923, 'dropout_rate3': 0.4216671710064199, 'dropout_rate4': 0.3659506634759446}. Best is trial 0 with value: 0.47560975609756095.\n",
      "[I 2024-03-11 20:50:11,577] Trial 1 finished with value: 0.4166666666666667 and parameters: {'lr': 0.007869876615352737, 'dropout_rate1': 0.2611965776763378, 'dropout_rate2': 0.4384039056949356, 'dropout_rate3': 0.1764438763141476, 'dropout_rate4': 0.35359936348147447}. Best is trial 0 with value: 0.47560975609756095.\n",
      "[I 2024-03-11 20:50:20,015] Trial 2 finished with value: 0.48577235772357724 and parameters: {'lr': 0.0004178720114277556, 'dropout_rate1': 0.12119691180810568, 'dropout_rate2': 0.497184925452879, 'dropout_rate3': 0.19950959631034937, 'dropout_rate4': 0.2393728452552098}. Best is trial 2 with value: 0.48577235772357724.\n",
      "[I 2024-03-11 20:50:28,181] Trial 3 finished with value: 0.3882113821138211 and parameters: {'lr': 0.011417728939412716, 'dropout_rate1': 0.1575809877462767, 'dropout_rate2': 0.2231660165965891, 'dropout_rate3': 0.4950800154265261, 'dropout_rate4': 0.11668851018313463}. Best is trial 2 with value: 0.48577235772357724.\n",
      "[I 2024-03-11 20:50:36,278] Trial 4 finished with value: 0.11991869918699187 and parameters: {'lr': 0.09526273360786952, 'dropout_rate1': 0.2694175627353225, 'dropout_rate2': 0.28208065032391766, 'dropout_rate3': 0.11511882436598891, 'dropout_rate4': 0.33631021855636045}. Best is trial 2 with value: 0.48577235772357724.\n",
      "[I 2024-03-11 20:50:44,290] Trial 5 finished with value: 0.11991869918699187 and parameters: {'lr': 0.03594611675634931, 'dropout_rate1': 0.3034126458061204, 'dropout_rate2': 0.35826176417094047, 'dropout_rate3': 0.10211105460205645, 'dropout_rate4': 0.31341653834612726}. Best is trial 2 with value: 0.48577235772357724.\n",
      "[I 2024-03-11 20:50:52,260] Trial 6 finished with value: 0.42276422764227645 and parameters: {'lr': 7.15068836470983e-05, 'dropout_rate1': 0.36203355958973127, 'dropout_rate2': 0.4291675434316625, 'dropout_rate3': 0.40618785895261195, 'dropout_rate4': 0.32836645068265935}. Best is trial 2 with value: 0.48577235772357724.\n",
      "[I 2024-03-11 20:51:00,286] Trial 7 finished with value: 0.11991869918699187 and parameters: {'lr': 0.08575089824431507, 'dropout_rate1': 0.10479491471727923, 'dropout_rate2': 0.21430297665143228, 'dropout_rate3': 0.4718580226451832, 'dropout_rate4': 0.13079813472531235}. Best is trial 2 with value: 0.48577235772357724.\n",
      "[I 2024-03-11 20:51:08,211] Trial 8 finished with value: 0.47764227642276424 and parameters: {'lr': 0.002239167029069661, 'dropout_rate1': 0.10454139180673981, 'dropout_rate2': 0.3362417031008924, 'dropout_rate3': 0.3923968650756182, 'dropout_rate4': 0.23983037035391683}. Best is trial 2 with value: 0.48577235772357724.\n",
      "[I 2024-03-11 20:51:16,611] Trial 9 finished with value: 0.36585365853658536 and parameters: {'lr': 0.013930186660118138, 'dropout_rate1': 0.2571297421163043, 'dropout_rate2': 0.20395285857244133, 'dropout_rate3': 0.255223613721321, 'dropout_rate4': 0.16660478345474955}. Best is trial 2 with value: 0.48577235772357724.\n",
      "[I 2024-03-11 20:51:24,903] Trial 10 finished with value: 0.2540650406504065 and parameters: {'lr': 1.0046161085282974e-05, 'dropout_rate1': 0.49924346698073613, 'dropout_rate2': 0.49433509651573837, 'dropout_rate3': 0.2844575039446549, 'dropout_rate4': 0.4802457013000438}. Best is trial 2 with value: 0.48577235772357724.\n",
      "[I 2024-03-11 20:51:33,084] Trial 11 finished with value: 0.45121951219512196 and parameters: {'lr': 0.0017412384851183205, 'dropout_rate1': 0.1619389285090869, 'dropout_rate2': 0.3115232835469248, 'dropout_rate3': 0.3480360810585038, 'dropout_rate4': 0.22642255540148665}. Best is trial 2 with value: 0.48577235772357724.\n",
      "[I 2024-03-11 20:51:41,189] Trial 12 finished with value: 0.45934959349593496 and parameters: {'lr': 0.0007323257383088321, 'dropout_rate1': 0.10017003157065915, 'dropout_rate2': 0.12176283488226847, 'dropout_rate3': 0.20846182252051088, 'dropout_rate4': 0.22961376500153047}. Best is trial 2 with value: 0.48577235772357724.\n",
      "[I 2024-03-11 20:51:49,186] Trial 13 finished with value: 0.48577235772357724 and parameters: {'lr': 0.002302869110788335, 'dropout_rate1': 0.17939962889128053, 'dropout_rate2': 0.47231051534483337, 'dropout_rate3': 0.35236517582046795, 'dropout_rate4': 0.23765529128897428}. Best is trial 2 with value: 0.48577235772357724.\n",
      "[I 2024-03-11 20:51:57,427] Trial 14 finished with value: 0.45934959349593496 and parameters: {'lr': 0.00017201082551960176, 'dropout_rate1': 0.19720464812874336, 'dropout_rate2': 0.49611796461131813, 'dropout_rate3': 0.3317176439048393, 'dropout_rate4': 0.26719954884320807}. Best is trial 2 with value: 0.48577235772357724.\n",
      "[I 2024-03-11 20:52:05,487] Trial 15 finished with value: 0.3882113821138211 and parameters: {'lr': 4.178893470114901e-05, 'dropout_rate1': 0.1967224747858547, 'dropout_rate2': 0.4568865643497113, 'dropout_rate3': 0.19749870091877575, 'dropout_rate4': 0.18452470881321648}. Best is trial 2 with value: 0.48577235772357724.\n",
      "[I 2024-03-11 20:52:13,714] Trial 16 finished with value: 0.491869918699187 and parameters: {'lr': 0.0006637232676955663, 'dropout_rate1': 0.1757864310009349, 'dropout_rate2': 0.3953015662948386, 'dropout_rate3': 0.28929601309308794, 'dropout_rate4': 0.43985081801842985}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:52:21,904] Trial 17 finished with value: 0.48577235772357724 and parameters: {'lr': 0.000600670955911026, 'dropout_rate1': 0.22369235358574016, 'dropout_rate2': 0.39543624982456804, 'dropout_rate3': 0.2420584657279099, 'dropout_rate4': 0.42794187502902925}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:52:29,622] Trial 18 finished with value: 0.4369918699186992 and parameters: {'lr': 0.00010037053072560907, 'dropout_rate1': 0.14144299410410316, 'dropout_rate2': 0.38925668969207516, 'dropout_rate3': 0.3020242486465544, 'dropout_rate4': 0.3944762977777641}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:52:37,093] Trial 19 finished with value: 0.3313008130081301 and parameters: {'lr': 2.3977820255012233e-05, 'dropout_rate1': 0.3029601752038427, 'dropout_rate2': 0.42457095841688486, 'dropout_rate3': 0.15272483923664998, 'dropout_rate4': 0.4917635880087033}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:52:44,687] Trial 20 finished with value: 0.4735772357723577 and parameters: {'lr': 0.0003442423227736374, 'dropout_rate1': 0.34212016328863204, 'dropout_rate2': 0.25637762998429614, 'dropout_rate3': 0.2468535407073395, 'dropout_rate4': 0.4396000811550332}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:52:52,326] Trial 21 finished with value: 0.4491869918699187 and parameters: {'lr': 0.003236756020763316, 'dropout_rate1': 0.19495665732600012, 'dropout_rate2': 0.47787629972126106, 'dropout_rate3': 0.3563523802118942, 'dropout_rate4': 0.27124375790172706}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:53:00,424] Trial 22 finished with value: 0.4268292682926829 and parameters: {'lr': 0.004238332560586015, 'dropout_rate1': 0.15366709566811432, 'dropout_rate2': 0.46353819972994215, 'dropout_rate3': 0.275392051728314, 'dropout_rate4': 0.19513603735625168}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:53:07,961] Trial 23 finished with value: 0.48577235772357724 and parameters: {'lr': 0.0008355464786235666, 'dropout_rate1': 0.23612602462307025, 'dropout_rate2': 0.41648425783070675, 'dropout_rate3': 0.3169756768914677, 'dropout_rate4': 0.2821587317976231}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:53:15,555] Trial 24 finished with value: 0.47560975609756095 and parameters: {'lr': 0.0012642772007422079, 'dropout_rate1': 0.14422854947474362, 'dropout_rate2': 0.373399721184974, 'dropout_rate3': 0.36553448485723206, 'dropout_rate4': 0.2919321763533098}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:53:23,131] Trial 25 finished with value: 0.4634146341463415 and parameters: {'lr': 0.000305864923040267, 'dropout_rate1': 0.17878961076815386, 'dropout_rate2': 0.4560745943141882, 'dropout_rate3': 0.2129472420632494, 'dropout_rate4': 0.15273079244617516}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:53:30,978] Trial 26 finished with value: 0.4329268292682927 and parameters: {'lr': 0.005920083206350874, 'dropout_rate1': 0.21969325880454152, 'dropout_rate2': 0.34365115407992, 'dropout_rate3': 0.1714494203260662, 'dropout_rate4': 0.20825405335651917}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:53:38,764] Trial 27 finished with value: 0.43902439024390244 and parameters: {'lr': 0.00017156865737452304, 'dropout_rate1': 0.12140622413755998, 'dropout_rate2': 0.4954189185066038, 'dropout_rate3': 0.44139927975482895, 'dropout_rate4': 0.24342346980413482}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:53:46,417] Trial 28 finished with value: 0.4715447154471545 and parameters: {'lr': 0.0016671496896686568, 'dropout_rate1': 0.1316325927729309, 'dropout_rate2': 0.44385823178812217, 'dropout_rate3': 0.38035751140060203, 'dropout_rate4': 0.3937032540886642}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:53:53,854] Trial 29 finished with value: 0.4715447154471545 and parameters: {'lr': 0.00045012835069535405, 'dropout_rate1': 0.4358671871654979, 'dropout_rate2': 0.407104466791113, 'dropout_rate3': 0.32705828571868895, 'dropout_rate4': 0.4494356156797089}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:54:01,343] Trial 30 finished with value: 0.4247967479674797 and parameters: {'lr': 0.00017676920590113963, 'dropout_rate1': 0.34413388766603803, 'dropout_rate2': 0.4702310159788816, 'dropout_rate3': 0.4409386589357291, 'dropout_rate4': 0.38191797827978996}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:54:08,940] Trial 31 finished with value: 0.4898373983739837 and parameters: {'lr': 0.000673935590997926, 'dropout_rate1': 0.22040446317303103, 'dropout_rate2': 0.38872204695486323, 'dropout_rate3': 0.2422911468872082, 'dropout_rate4': 0.42757656115488735}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:54:16,452] Trial 32 finished with value: 0.491869918699187 and parameters: {'lr': 0.001153437662824187, 'dropout_rate1': 0.1798474861273578, 'dropout_rate2': 0.3806514765011956, 'dropout_rate3': 0.2352816133948279, 'dropout_rate4': 0.46300653376369083}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:54:23,926] Trial 33 finished with value: 0.4735772357723577 and parameters: {'lr': 0.0002239664210697321, 'dropout_rate1': 0.24848012884960996, 'dropout_rate2': 0.31634844762280145, 'dropout_rate3': 0.22868848196211533, 'dropout_rate4': 0.46282277347069833}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:54:31,525] Trial 34 finished with value: 0.48577235772357724 and parameters: {'lr': 0.001023203870000557, 'dropout_rate1': 0.277019627447054, 'dropout_rate2': 0.3705192179182564, 'dropout_rate3': 0.1410812396792146, 'dropout_rate4': 0.4144365607087586}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:54:39,649] Trial 35 finished with value: 0.4735772357723577 and parameters: {'lr': 0.00048010057516775757, 'dropout_rate1': 0.16585343827207483, 'dropout_rate2': 0.2784617408317332, 'dropout_rate3': 0.2728401828351167, 'dropout_rate4': 0.3676569593012668}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:54:47,437] Trial 36 finished with value: 0.4268292682926829 and parameters: {'lr': 9.362420836534941e-05, 'dropout_rate1': 0.2116531771523553, 'dropout_rate2': 0.33872607583364794, 'dropout_rate3': 0.17804467639696364, 'dropout_rate4': 0.46816110490658613}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:54:55,261] Trial 37 finished with value: 0.3882113821138211 and parameters: {'lr': 0.008184092426184127, 'dropout_rate1': 0.1213256364508073, 'dropout_rate2': 0.3584326321582293, 'dropout_rate3': 0.2250949981541514, 'dropout_rate4': 0.3543665714513008}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:55:03,003] Trial 38 finished with value: 0.46747967479674796 and parameters: {'lr': 0.00096202241253677, 'dropout_rate1': 0.17909020537765913, 'dropout_rate2': 0.394043512563489, 'dropout_rate3': 0.18726784315794645, 'dropout_rate4': 0.41322751695284804}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:55:10,823] Trial 39 finished with value: 0.3556910569105691 and parameters: {'lr': 0.015499544266050231, 'dropout_rate1': 0.2682664518527263, 'dropout_rate2': 0.28706410354189926, 'dropout_rate3': 0.25897156470115157, 'dropout_rate4': 0.33607767249659476}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:55:18,441] Trial 40 finished with value: 0.45121951219512196 and parameters: {'lr': 0.0033360625515943773, 'dropout_rate1': 0.2078268743786408, 'dropout_rate2': 0.4272604525649394, 'dropout_rate3': 0.12813766506028662, 'dropout_rate4': 0.3121372311561058}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:55:26,071] Trial 41 finished with value: 0.45934959349593496 and parameters: {'lr': 0.002114063521980649, 'dropout_rate1': 0.16898596966319263, 'dropout_rate2': 0.4396523200685872, 'dropout_rate3': 0.2856361973189729, 'dropout_rate4': 0.4949777209890597}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:55:33,620] Trial 42 finished with value: 0.483739837398374 and parameters: {'lr': 0.0005479321735652038, 'dropout_rate1': 0.1898236291736118, 'dropout_rate2': 0.48345725444552684, 'dropout_rate3': 0.29573799130910955, 'dropout_rate4': 0.2541071931904459}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:55:41,219] Trial 43 finished with value: 0.4451219512195122 and parameters: {'lr': 0.0013232069479271363, 'dropout_rate1': 0.12510595893544246, 'dropout_rate2': 0.376840870015816, 'dropout_rate3': 0.22803331329096238, 'dropout_rate4': 0.10113940598808052}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:55:48,885] Trial 44 finished with value: 0.4532520325203252 and parameters: {'lr': 0.002174500530005386, 'dropout_rate1': 0.2359546705260784, 'dropout_rate2': 0.44308664364281897, 'dropout_rate3': 0.3064105730907362, 'dropout_rate4': 0.4576671973777644}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:55:56,561] Trial 45 finished with value: 0.12398373983739837 and parameters: {'lr': 0.025634450014757563, 'dropout_rate1': 0.14861545457241093, 'dropout_rate2': 0.41024012858208075, 'dropout_rate3': 0.2612212213376087, 'dropout_rate4': 0.21422221787963264}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:56:04,298] Trial 46 finished with value: 0.4695121951219512 and parameters: {'lr': 0.00037418402165647827, 'dropout_rate1': 0.2870173356533121, 'dropout_rate2': 0.16467326338232588, 'dropout_rate3': 0.3411165854890902, 'dropout_rate4': 0.42767373390739377}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:56:11,942] Trial 47 finished with value: 0.4695121951219512 and parameters: {'lr': 0.0007243692221588406, 'dropout_rate1': 0.17016648977103002, 'dropout_rate2': 0.32331007964380615, 'dropout_rate3': 0.20485097560492171, 'dropout_rate4': 0.30383427071963914}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:56:19,752] Trial 48 finished with value: 0.4817073170731707 and parameters: {'lr': 0.0002448012458827107, 'dropout_rate1': 0.11475758208236864, 'dropout_rate2': 0.3534322353629801, 'dropout_rate3': 0.16050469254245397, 'dropout_rate4': 0.479543402086864}. Best is trial 16 with value: 0.491869918699187.\n",
      "[I 2024-03-11 20:56:27,907] Trial 49 finished with value: 0.3943089430894309 and parameters: {'lr': 0.005002616475171081, 'dropout_rate1': 0.2337671399397267, 'dropout_rate2': 0.453864234581423, 'dropout_rate3': 0.40363059748533786, 'dropout_rate4': 0.1650386673025615}. Best is trial 16 with value: 0.491869918699187.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 50\n",
      "Best trial: {'lr': 0.0006637232676955663, 'dropout_rate1': 0.1757864310009349, 'dropout_rate2': 0.3953015662948386, 'dropout_rate3': 0.28929601309308794, 'dropout_rate4': 0.43985081801842985}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize', study_name=\"CNN\")\n",
    "study.optimize(objective, n_trials=50)  # You can adjust the number of trials\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T20:56:27.911758Z",
     "start_time": "2024-03-11T20:49:54.376449Z"
    }
   },
   "id": "11eff44aa11bfdb5",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d4d28e6ff32e0e03"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
