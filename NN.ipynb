{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_pytorch_model(model, dataloaders, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    performance = {}\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "            if phase not in dataloaders:  # Skip if DataLoader is not provided for the phase\n",
    "                continue\n",
    "            correct, total = 0, 0\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            accuracy = correct / total\n",
    "            performance[phase + '_accuracy'] = accuracy\n",
    "            print(f'Accuracy of the {model.__class__.__name__} model on the {phase} set: {accuracy:.2f}')\n",
    "    # return performance\n",
    "\n",
    "def evaluate_sklearn_model(model, X_train, Y_train, X_test, Y_test):\n",
    "    performance = {}\n",
    "    for phase, X, Y in [('train', X_train, Y_train), ('test', X_test, Y_test)]:\n",
    "        predicted = model.predict(X)\n",
    "        accuracy = np.mean(predicted == Y)\n",
    "        performance[phase + '_accuracy'] = accuracy\n",
    "        print(f'Accuracy of the {model.__class__.__name__} model on the {phase} set: {accuracy:.2f}')\n",
    "    return performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def map_predictions_to_genres(predictions, label_encoder):\n",
    "    genre_predictions = label_encoder.inverse_transform(predictions)\n",
    "    return genre_predictions\n",
    "\n",
    "def make_predictions_pytorch(model, X_test_tensor, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    X_test_tensor = X_test_tensor.to(device)\n",
    "    with torch.no_grad():  # No need to track the gradients\n",
    "        outputs = model(X_test_tensor)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "    # Convert predictions to CPU and numpy for easier handling\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    return predictions\n",
    "\n",
    "def make_predictions_sklearn(model, X_test_scaled):\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "    return predictions\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "116bb345f787cde2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2ec81c44fe8cd25"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_layers=2, hidden_size=100):\n",
    "        super(CustomNN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            if i == 0:\n",
    "                self.layers.append(nn.Linear(input_size, hidden_size))\n",
    "            else:\n",
    "                self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            self.layers.append(nn.ReLU())\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1579b68d16c5e77a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, val_loader, device, optimizer, criterion, epochs=10):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_accuracy = correct / total\n",
    "    return val_accuracy\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "642606333cf1db40"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import optuna\n",
    "all_models = []\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 50, 500)\n",
    "    \n",
    "    # Model initialization\n",
    "    model = CustomNN(input_size=X_train.shape[1], num_classes=len(np.unique(Y_train)),\n",
    "                     num_layers=num_layers, hidden_size=hidden_size).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train and validate\n",
    "    val_accuracy = train_and_validate(model, train_loader, val_loader, device, optimizer, criterion, epochs=10)\n",
    "    \n",
    "    # Save the model and trial information\n",
    "    all_models.append({'trial_id': trial.number, 'model': model, 'val_accuracy': val_accuracy})\n",
    "    \n",
    "    return val_accuracy\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9635e0d36747568"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize', study_name='MLP')\n",
    "study.optimize(objective, n_trials=50)  # Adjust the number of trials as needed\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"Value: {trial.value}\")\n",
    "print(\"Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b418a3195a4b1f6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Find the best model based on validation accuracy\n",
    "best_model_info = max(all_models, key=lambda x: x['val_accuracy'])\n",
    "best_model = best_model_info['model']\n",
    "\n",
    "# Test the best model\n",
    "evaluate_pytorch_model(best_model, dataloaders={'train': train_loader, 'val': val_loader, 'test': test_loader}, device=device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca2f2f4e000c1468"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Try more complex type of MLP that includes batch norm and dropout layers, weight decay"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "286641431f273bd8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class AdvancedCustomNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_layers=2, hidden_size=100, dropout_rate=0.0, use_batch_norm=False):\n",
    "        super(AdvancedCustomNN, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            if i == 0:\n",
    "                layers.append(nn.Linear(input_size, hidden_size))\n",
    "            else:\n",
    "                layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            if use_batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "                \n",
    "        layers.append(nn.Linear(hidden_size, num_classes))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e4d930cfd5f49c1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "all_advanced_mlps = []\n",
    "def advanced_objective(trial):\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 8)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 50, 600)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "    use_batch_norm = trial.suggest_categorical('use_batch_norm', [True, False])\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-1, log=True)\n",
    "    \n",
    "    model = AdvancedCustomNN(input_size=X_train.shape[1], num_classes=len(np.unique(Y_train)),\n",
    "                             num_layers=num_layers, hidden_size=hidden_size,\n",
    "                             dropout_rate=dropout_rate, use_batch_norm=use_batch_norm).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    val_accuracy = train_and_validate(model, train_loader, val_loader, device, optimizer, criterion, epochs=10)\n",
    "    # Save the model and trial information\n",
    "    all_advanced_mlps.append({'trial_id': trial.number, 'model': model, 'val_accuracy': val_accuracy})\n",
    "    \n",
    "    return val_accuracy\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a96f6760c257f1da"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize', study_name=\"MLP Advanced\")\n",
    "study.optimize(advanced_objective, n_trials=100)  # Adjust n_trials based on computational resources\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"Value: {trial.value}\")\n",
    "print(\"Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e71d7839bcbe1052"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Find the best model based on validation accuracy\n",
    "best_adv_mlp_info = max(all_advanced_mlps, key=lambda x: x['val_accuracy'])\n",
    "best_adv_mlp = best_adv_mlp_info['model']\n",
    "\n",
    "evaluate_pytorch_model(best_adv_mlp, dataloaders={'train': train_loader, 'val': val_loader, 'test': test_loader}, device=device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9e2dd57ba78b589"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Manually experiment with MLP Architectures"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "732955b1a57d16ec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "def train_and_validate_with_plot(model, train_loader, val_loader, device, optimizer, criterion, epochs=10):\n",
    "    # Lists to keep track of losses and timing\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        # Calculate and store the average training loss\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        running_loss = 0.0  # Reset running loss for validation\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        total, correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)  # Corrected to use labels\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            # Calculate and store the average validation loss\n",
    "            val_losses.append(running_loss / len(val_loader))\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = (end_time - start_time) / 60  # Time in minutes\n",
    "    \n",
    "    # Plotting the training and validation loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    val_accuracy = correct / total\n",
    "    print(f\"Training completed in: {elapsed_time:.2f} minutes\")\n",
    "    return val_accuracy\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e8328addd6a711a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ManualNN(nn.Module):\n",
    "    def __init__(self, input_size=518, num_classes=8, dropout_rate=0.3, hidden_units=[256, 128, 64, 32]):\n",
    "        super(ManualNN, self).__init__()\n",
    "\n",
    "        # Define the layers\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.bn_layers = nn.ModuleList([nn.BatchNorm1d(hidden_units[i]) for i in range(len(hidden_units))])\n",
    "\n",
    "        self.input_layer = nn.Linear(input_size, hidden_units[0])\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_units[i], hidden_units[i+1]) for i in range(len(hidden_units)-1)])\n",
    "        self.output_layer = nn.Linear(hidden_units[-1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through each layer\n",
    "        x = self.bn_layers[0](self.input_layer(x))\n",
    "        x = F.relu(x)\n",
    "        for i, layer in enumerate(self.hidden_layers):\n",
    "            x = self.bn_layers[i+1](layer(x))\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e756d36c6bb75137"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "NN = ManualNN(hidden_units=[2056] * 4 + [1028] * 4 + [512]*4 + [256]*4 + [128]*4 + [64]*4 + [32,16], dropout_rate=0.4).to(device)\n",
    "# Define optimizer and loss function\n",
    "# optimizer = torch.optim.Adam(NN.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.SGD(NN.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and validate the model\n",
    "epochs = 400\n",
    "val_accuracy = train_and_validate_with_plot(NN, train_loader, val_loader, device, optimizer, criterion, epochs)\n",
    "evaluate_pytorch_model(NN, dataloaders={'train': train_loader, 'val': val_loader, 'test': test_loader}, device=device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "780a145e8c62fe21"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_and_validate_with_plot_es(model, train_loader, val_loader, device, optimizer, criterion, epochs=10, patience=5):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "        average_val_loss = running_loss / len(val_loader)\n",
    "        val_losses.append(average_val_loss)\n",
    "\n",
    "        # Early Stopping\n",
    "        if average_val_loss < best_val_loss:\n",
    "            best_val_loss = average_val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        if epochs_no_improve == patience:\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "\n",
    "    # Plot losses\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, train_losses, val_losses\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bd1df6d277a8a2b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Try varying batch sizes:\n",
    "bs = 64\n",
    "train_loader_vbs = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "val_loader_vbs = DataLoader(val_dataset, batch_size=bs, shuffle=False)\n",
    "test_loader_vbs = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "# Instantiate #10360 works fairly well\n",
    "NN = ManualNN(hidden_units=[268324] + [33540]*0 + [256]*0 + [128] + [64]*1 + [32]* 1 + [16], dropout_rate=0.5).to(device)\n",
    "# Define optimizer and loss function\n",
    "# optimizer = torch.optim.Adam(NN.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.SGD(NN.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.MSE()\n",
    "\n",
    "# Train and evaluate the model\n",
    "epochs = 500\n",
    "patience = 50\n",
    "val_acc = train_and_validate_with_plot_es(NN, train_loader_vbs, val_loader_vbs, device, optimizer, criterion, epochs, patience)\n",
    "evaluate_pytorch_model(NN, dataloaders={'train': train_loader, 'val': val_loader, 'test': test_loader}, device=device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "922a2cd11197394d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print([518]  + [10360] + [5,180]*0 + [512] + [128] + [64]*1 + [16])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4ffc3bab6654be5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print([518*1000] + [5,180]*0 + [256]*0 + [128]*0 + [64]*0 + [32]*1 + [16]*0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f097ee5cda0074a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
