{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup Cell"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 different classes: Electronic, Experimental, Folk, Hip-Hop, Instrumental, International, Pop or Rock.\n",
      "objective 1: construct a classifier which, based on the features of a song, predicts its genre\n",
      "objective 2: estimate its generalisation error under the 0â€“1 loss.\n",
      "Features are real-valued, correspond to summary statistics (mean, sd, skewness, kurtosis, median, min, max) of \n",
      "time series of various music features, such as the chromagram or the Mel-frequency cepstrum.\n",
      "Feature description: \n",
      "\n",
      "Feature description: \n",
      "chroma_cens: Chroma Energy Normalized (CENS, 12 chroma) - 84 features\n",
      "chroma_cqt: Constant-Q chromagram (12 chroma) - 84 features\n",
      "chroma_stft: Chromagram (12 chroma) - 84 features\n",
      "mfcc: Mel-frequency cepstrum (20 coefficients) - 140 features\n",
      "rmse: Root-mean-square - 7 features\n",
      "spectral_bandwidth: Spectral bandwidth - 7 features\n",
      "spectral_centroid: Spectral centroid - 7 features\n",
      "spectral_contrast: Spectral contrast (7 frequency bands) - 49 features\n",
      "spectral_rolloff: Roll-off frequency - 7 features\n",
      "tonnetz: Tonal centroid features (6 features) - 42 features\n",
      "zcr: Zero-crossing rate - 7 features\n",
      "x_train: 6000 rows on 518 columns\n",
      "Objects loaded: x_train, x_test, y_train as pd dataframes, x_train_np, x_test_np, y_train_np as NP arrays\n",
      "function generate_submission_csv(genre_predictions, filename='submission.csv') available\n"
     ]
    }
   ],
   "source": [
    "%run 'Setup.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Splitting, Scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/max/anaconda3/envs/sml-practical/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_np.ravel()) #\n",
    "\n",
    "# Split training data into training and temporary validation sets\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(x_train, y_train_encoded, test_size=0.4, random_state=42)\n",
    "\n",
    "# Split the temporary validation set into validation and test sets\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_real_test_scaled = scaler.transform(x_test_np)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Function Split Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def split_features_by_type(X, feature_structure):\n",
    "    \"\"\"\n",
    "    Splits the dataset into subsets based on the feature structure provided.\n",
    "\n",
    "    :param X: numpy array, the dataset to be split (features only)\n",
    "    :param feature_structure: dict, keys are feature names and values are the number of features of that type\n",
    "    :return: dict of feature subsets\n",
    "    \"\"\"\n",
    "    feature_subsets = {}\n",
    "    start_idx = 0\n",
    "\n",
    "    for feature_name, feature_count in feature_structure.items():\n",
    "        end_idx = start_idx + feature_count\n",
    "        feature_subsets[feature_name] = X[:, start_idx:end_idx]\n",
    "        start_idx = end_idx\n",
    "\n",
    "    return feature_subsets\n",
    "\n",
    "# Define the structure of your features based on the information you've provided\n",
    "feature_structure = {\n",
    "    'chroma_cens': 84,\n",
    "    'chroma_cqt': 84,\n",
    "    'chroma_stft': 84,\n",
    "    'mfcc': 140,\n",
    "    'rmse': 7,\n",
    "    'spectral_bandwidth': 7,\n",
    "    'spectral_centroid': 7,\n",
    "    'spectral_contrast': 49,\n",
    "    'spectral_rolloff': 7,\n",
    "    'tonnetz': 42,\n",
    "    'zcr': 7\n",
    "}\n",
    "\n",
    "# Example usage with a hypothetical dataset X_train_scaled\n",
    "# This would be your preprocessed and scaled training data as a NumPy array\n",
    "feature_subsets = split_features_by_type(X_train_scaled, feature_structure)\n",
    "\n",
    "# Now feature_subsets is a dictionary where, for example,\n",
    "# feature_subsets['mfcc'] contains only the MFCC features of the dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest Feature Subset Fit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy for chroma_cens features: 0.29\n",
      "Validation accuracy for chroma_cqt features: 0.33\n",
      "Validation accuracy for chroma_stft features: 0.3883333333333333\n",
      "Validation accuracy for mfcc features: 0.5133333333333333\n",
      "Validation accuracy for rmse features: 0.26666666666666666\n",
      "Validation accuracy for spectral_bandwidth features: 0.33166666666666667\n",
      "Validation accuracy for spectral_centroid features: 0.3525\n",
      "Validation accuracy for spectral_contrast features: 0.4608333333333333\n",
      "Validation accuracy for spectral_rolloff features: 0.3425\n",
      "Validation accuracy for tonnetz features: 0.2966666666666667\n",
      "Validation accuracy for zcr features: 0.3325\n",
      "Test accuracy with combined Random Forest models using weighted voting: 0.5408333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming the preprocessing and data splitting is already done as per your provided code\n",
    "\n",
    "# Initialize a dictionary to store your best Random Forest models for each feature subset\n",
    "best_rf_models = {}\n",
    "\n",
    "# Train a Random Forest model for each feature subset\n",
    "for feature_name, X_train_subset in feature_subsets.items():\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train_subset, Y_train)\n",
    "    best_rf_models[feature_name] = rf_model\n",
    "\n",
    "# Evaluate each model on the validation set and calculate weights\n",
    "weights = []\n",
    "val_feature_subsets = split_features_by_type(X_val_scaled, feature_structure)\n",
    "\n",
    "for feature_name, model in best_rf_models.items():\n",
    "    X_val_subset = val_feature_subsets[feature_name]\n",
    "    val_accuracy = model.score(X_val_subset, Y_val)\n",
    "    weights.append(val_accuracy)\n",
    "    print(f\"Validation accuracy for {feature_name} features: {val_accuracy}\")\n",
    "\n",
    "# Normalize weights\n",
    "weights = np.array(weights) / np.sum(weights)\n",
    "\n",
    "# Split the test set using the same feature structure and prepare for weighted predictions\n",
    "test_feature_subsets = split_features_by_type(X_test_scaled, feature_structure)\n",
    "weighted_test_predictions = np.zeros((X_test_scaled.shape[0], len(np.unique(Y_train))), dtype=float)\n",
    "\n",
    "for i, (feature_name, model) in enumerate(best_rf_models.items()):\n",
    "    X_test_subset = test_feature_subsets[feature_name]\n",
    "    predictions = model.predict_proba(X_test_subset)\n",
    "    weighted_predictions = predictions * weights[i]\n",
    "    weighted_test_predictions += weighted_predictions\n",
    "\n",
    "# Combine weighted predictions\n",
    "combined_test_predictions = np.argmax(weighted_test_predictions, axis=1)\n",
    "\n",
    "# Calculate and print test accuracy\n",
    "test_accuracy = np.mean(combined_test_predictions == Y_test)\n",
    "print(f\"Test accuracy with combined Random Forest models using weighted voting: {test_accuracy}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KNN Feature Subset Fit (from KNN.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K for chroma_cens features: 9 with cross-validation score: 0.2663888888888889\n",
      "Best K for chroma_cqt features: 13 with cross-validation score: 0.27361111111111114\n",
      "Best K for chroma_stft features: 13 with cross-validation score: 0.30194444444444446\n",
      "Best K for mfcc features: 15 with cross-validation score: 0.46611111111111103\n",
      "Best K for rmse features: 15 with cross-validation score: 0.23555555555555552\n",
      "Best K for spectral_bandwidth features: 15 with cross-validation score: 0.29083333333333333\n",
      "Best K for spectral_centroid features: 11 with cross-validation score: 0.32166666666666666\n",
      "Best K for spectral_contrast features: 12 with cross-validation score: 0.40861111111111115\n",
      "Best K for spectral_rolloff features: 12 with cross-validation score: 0.3061111111111111\n",
      "Best K for tonnetz features: 6 with cross-validation score: 0.2725000000000001\n",
      "Best K for zcr features: 14 with cross-validation score: 0.30583333333333335\n",
      "Validation accuracy with combined KNN models: 0.4725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Dictionary to store the trained KNN models for each feature subset\n",
    "knn_models = {}\n",
    "\n",
    "# Train a KNN model for each feature subset\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Dictionary to store the best KNN models for each feature subset\n",
    "best_knn_models = {}\n",
    "\n",
    "# Train a KNN model for each feature subset and find the best k using cross-validation\n",
    "for feature_name, X_subset in feature_subsets.items():\n",
    "    best_score = 0\n",
    "    best_k = 1\n",
    "    # Try different values of k\n",
    "    for k in range(1, 16):  # Let's try k from 1 to 15 as an example\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = cross_val_score(knn, X_subset, Y_train, cv=5)\n",
    "        mean_score = scores.mean()\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_k = k\n",
    "\n",
    "    # Train a new KNN model on the full training set with the best k\n",
    "    best_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    best_knn.fit(X_subset, Y_train)\n",
    "    best_knn_models[feature_name] = best_knn\n",
    "    print(f\"Best K for {feature_name} features: {best_k} with cross-validation score: {best_score}\")\n",
    "\n",
    "# Now best_knn_models dictionary contains the best KNN model for each feature subset\n",
    "\n",
    "\n",
    "# Now knn_models dictionary contains a trained KNN model for each feature subset\n",
    "# For example, knn_models['mfcc'] is the KNN model trained on the MFCC features\n",
    "\n",
    "# To make predictions, use the corresponding model for each feature subset\n",
    "# For instance, for MFCC features:\n",
    "# predictions_mfcc = knn_models['mfcc'].predict(feature_subsets['mfcc'])\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Assume we have a validation set X_val_scaled\n",
    "# Split it using the same function we defined earlier\n",
    "val_feature_subsets = split_features_by_type(X_val_scaled, feature_structure)\n",
    "\n",
    "# Gather predictions from all models on the validation set\n",
    "val_predictions = []\n",
    "for feature_name, model in best_knn_models.items():\n",
    "    # Ensure that we predict on the correct feature subset\n",
    "    X_val_subset = val_feature_subsets[feature_name]\n",
    "    predictions = model.predict(X_val_subset)\n",
    "    val_predictions.append(predictions)\n",
    "\n",
    "# Combine predictions using majority voting\n",
    "combined_val_predictions = mode(val_predictions, axis=0).mode\n",
    "\n",
    "# Calculate accuracy or any other metric based on the combined predictions\n",
    "val_accuracy = np.mean(combined_val_predictions.ravel() == Y_val)\n",
    "print(f\"Validation accuracy with combined KNN models: {val_accuracy}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stacked Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RF and KNN Stacked"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with stacked RF and KNN models: 0.5716666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data for the meta-model\n",
    "# Generate predictions from RF and KNN models on the validation set\n",
    "X_meta_train = np.hstack([\n",
    "    np.concatenate([\n",
    "        model.predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis]  # Add a new axis for stacking\n",
    "        for model in (best_rf_models[feature_name], best_knn_models[feature_name])\n",
    "    ], axis=2).mean(axis=2)  # Average predictions from RF and KNN models for each feature subset\n",
    "    for feature_name in feature_subsets.keys()\n",
    "]).reshape(len(Y_val), -1)  # Reshape to have a standard 2D array\n",
    "\n",
    "# Train the meta-model\n",
    "meta_model = LogisticRegression(random_state=42)\n",
    "meta_model.fit(X_meta_train, Y_val)\n",
    "\n",
    "# Prepare test data in a similar manner\n",
    "X_meta_test = np.hstack([\n",
    "    np.concatenate([\n",
    "        model.predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis]\n",
    "        for model in (best_rf_models[feature_name], best_knn_models[feature_name])\n",
    "    ], axis=2).mean(axis=2)\n",
    "    for feature_name in feature_subsets.keys()\n",
    "]).reshape(len(Y_test), -1)\n",
    "\n",
    "# Make final predictions with the meta-model\n",
    "final_predictions = meta_model.predict(X_meta_test)\n",
    "\n",
    "# Calculate and print the test accuracy\n",
    "test_accuracy = accuracy_score(Y_test, final_predictions)\n",
    "print(f\"Test accuracy with stacked RF and KNN models: {test_accuracy}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RF, KNN, and LR Stacked"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with stacked RF, KNN, and LR models: 0.5983333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize a dictionary to store the logistic regression models for each feature subset\n",
    "best_lr_models = {}\n",
    "\n",
    "# Train a logistic regression model for each feature subset\n",
    "for feature_name, X_train_subset in feature_subsets.items():\n",
    "    lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    lr_model.fit(X_train_subset, Y_train)\n",
    "    best_lr_models[feature_name] = lr_model\n",
    "\n",
    "# Update the preparation of the data for the meta-model to include logistic regression predictions\n",
    "X_meta_train = np.hstack([\n",
    "    np.concatenate([\n",
    "        best_rf_models[feature_name].predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_knn_models[feature_name].predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_lr_models[feature_name].predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis]\n",
    "    ], axis=2).mean(axis=2)  # Average predictions from RF, KNN, and LR models for each feature subset\n",
    "    for feature_name in feature_subsets.keys()\n",
    "]).reshape(len(Y_val), -1)  # Reshape to have a standard 2D array\n",
    "\n",
    "# Train the meta-model with the updated training data\n",
    "meta_model.fit(X_meta_train, Y_val)\n",
    "\n",
    "# Update the preparation of the test data in a similar manner to include logistic regression predictions\n",
    "X_meta_test = np.hstack([\n",
    "    np.concatenate([\n",
    "        best_rf_models[feature_name].predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_knn_models[feature_name].predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_lr_models[feature_name].predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis]\n",
    "    ], axis=2).mean(axis=2)\n",
    "    for feature_name in feature_subsets.keys()\n",
    "]).reshape(len(Y_test), -1)\n",
    "\n",
    "# Make final predictions with the updated meta-model\n",
    "final_predictions = meta_model.predict(X_meta_test)\n",
    "\n",
    "# Calculate and print the test accuracy with the inclusion of logistic regression models\n",
    "test_accuracy = accuracy_score(Y_test, final_predictions)\n",
    "print(f\"Test accuracy with stacked RF, KNN, and LR models: {test_accuracy}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Stacked Bootstrap"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with bootstrapped and stacked RF, KNN, and LR models: 0.5933333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Define the number of bootstrap samples and models\n",
    "n_bootstrap_samples = 10\n",
    "\n",
    "# Placeholder for trained bootstrap models\n",
    "bootstrap_models_rf = {feature_name: [] for feature_name in feature_subsets.keys()}\n",
    "bootstrap_models_knn = {feature_name: [] for feature_name in feature_subsets.keys()}\n",
    "bootstrap_models_lr = {feature_name: [] for feature_name in feature_subsets.keys()}\n",
    "\n",
    "# Train bootstrap models for RandomForest\n",
    "for feature_name, X_train_subset in feature_subsets.items():\n",
    "    for _ in range(n_bootstrap_samples):\n",
    "        # Create a bootstrap sample\n",
    "        X_boot, Y_boot = resample(X_train_subset, Y_train)\n",
    "        # Initialize and train the model on the bootstrap sample\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "        model.fit(X_boot, Y_boot)\n",
    "        bootstrap_models_rf[feature_name].append(model)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# Train bootstrap models for KNN\n",
    "for feature_name, X_train_subset in feature_subsets.items():\n",
    "    for _ in range(n_bootstrap_samples):\n",
    "        X_boot, Y_boot = resample(X_train_subset, Y_train)\n",
    "        knn_model = KNeighborsClassifier()\n",
    "        knn_model.fit(X_boot, Y_boot)\n",
    "        bootstrap_models_knn[feature_name].append(knn_model)\n",
    "\n",
    "# Train bootstrap models for Logistic Regression\n",
    "for feature_name, X_train_subset in feature_subsets.items():\n",
    "    for _ in range(n_bootstrap_samples):\n",
    "        X_boot, Y_boot = resample(X_train_subset, Y_train)\n",
    "        lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "        lr_model.fit(X_boot, Y_boot)\n",
    "        bootstrap_models_lr[feature_name].append(lr_model)\n",
    "\n",
    "# Generate averaged predictions for the validation set\n",
    "# This assumes `val_feature_subsets` is already prepared similarly to `feature_subsets`\n",
    "X_meta_train = np.hstack([\n",
    "    np.mean([\n",
    "        np.mean([model.predict_proba(val_feature_subsets[feature_name]) for model in models], axis=0)\n",
    "        for models in (bootstrap_models_rf[feature_name], bootstrap_models_knn[feature_name], bootstrap_models_lr[feature_name])\n",
    "    ], axis=0)\n",
    "    for feature_name in feature_subsets.keys()\n",
    "]).reshape(len(Y_val), -1)\n",
    "\n",
    "# Train the meta-model\n",
    "meta_model.fit(X_meta_train, Y_val)\n",
    "\n",
    "# Assuming `test_feature_subsets` is prepared, generate predictions for the test set\n",
    "X_meta_test = np.hstack([\n",
    "    np.mean([\n",
    "        np.mean([model.predict_proba(test_feature_subsets[feature_name]) for model in models], axis=0)\n",
    "        for models in (bootstrap_models_rf[feature_name], bootstrap_models_knn[feature_name], bootstrap_models_lr[feature_name])\n",
    "    ], axis=0)\n",
    "    for feature_name in feature_subsets.keys()\n",
    "]).reshape(len(Y_test), -1)\n",
    "\n",
    "# Final predictions with the meta-model\n",
    "final_predictions = meta_model.predict(X_meta_test)\n",
    "\n",
    "# Calculate and print the test accuracy\n",
    "test_accuracy = accuracy_score(Y_test, final_predictions)\n",
    "print(f\"Test accuracy with bootstrapped and stacked RF, KNN, and LR models: {test_accuracy}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with the best model from each feature subset ensemble: 0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `feature_subsets`, `X_val_scaled`, and `Y_val` are already defined\n",
    "\n",
    "# Step 1: Train models on each feature subset\n",
    "model_types = ['KNN', 'RF', 'LR']\n",
    "best_models = {}\n",
    "\n",
    "for feature_name, X_train_subset in feature_subsets.items():\n",
    "    # Track the best model for this subset\n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    X_val_subset = val_feature_subsets[feature_name]\n",
    "\n",
    "    # KNN Model\n",
    "    knn_model = KNeighborsClassifier()\n",
    "    knn_model.fit(X_train_subset, Y_train)\n",
    "    knn_accuracy = knn_model.score(X_val_subset, Y_val)\n",
    "\n",
    "    if knn_accuracy > best_accuracy:\n",
    "        best_accuracy = knn_accuracy\n",
    "        best_model = ('KNN', knn_model)\n",
    "\n",
    "    # RF Model\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train_subset, Y_train)\n",
    "    rf_accuracy = rf_model.score(X_val_subset, Y_val)\n",
    "\n",
    "    if rf_accuracy > best_accuracy:\n",
    "        best_accuracy = rf_accuracy\n",
    "        best_model = ('RF', rf_model)\n",
    "\n",
    "    # LR Model\n",
    "    lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    lr_model.fit(X_train_subset, Y_train)\n",
    "    lr_accuracy = lr_model.score(X_val_subset, Y_val)\n",
    "\n",
    "    if lr_accuracy > best_accuracy:\n",
    "        best_accuracy = lr_accuracy\n",
    "        best_model = ('LR', lr_model)\n",
    "\n",
    "    best_models[feature_name] = best_model\n",
    "\n",
    "# Step 2: Evaluate and select the best model per subset (already done in the loop)\n",
    "\n",
    "# Step 3: Ensemble selected models for final prediction\n",
    "# Generate predictions for each selected model on the test set\n",
    "ensemble_predictions = np.zeros((len(Y_test), len(np.unique(Y_train))))\n",
    "\n",
    "for feature_name, (model_type, model) in best_models.items():\n",
    "    X_test_subset = test_feature_subsets[feature_name]\n",
    "    predictions = model.predict_proba(X_test_subset)\n",
    "    ensemble_predictions += predictions\n",
    "\n",
    "# Final ensemble prediction\n",
    "final_predictions = np.argmax(ensemble_predictions, axis=1)\n",
    "\n",
    "# Calculate and print the test accuracy\n",
    "test_accuracy = accuracy_score(Y_test, final_predictions)\n",
    "print(f\"Test accuracy with the best model from each feature subset ensemble: {test_accuracy}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
