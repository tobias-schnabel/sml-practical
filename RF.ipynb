{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup Cell"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 different classes: Electronic, Experimental, Folk, Hip-Hop, Instrumental, International, Pop or Rock.\n",
      "objective 1: construct a classifier which, based on the features of a song, predicts its genre\n",
      "objective 2: estimate its generalisation error under the 0â€“1 loss.\n",
      "Features are real-valued, correspond to summary statistics (mean, sd, skewness, kurtosis, median, min, max) of \n",
      "time series of various music features, such as the chromagram or the Mel-frequency cepstrum.\n",
      "Feature description: \n",
      "\n",
      "Feature description: \n",
      "chroma_cens: Chroma Energy Normalized (CENS, 12 chroma) - 84 features\n",
      "chroma_cqt: Constant-Q chromagram (12 chroma) - 84 features\n",
      "chroma_stft: Chromagram (12 chroma) - 84 features\n",
      "mfcc: Mel-frequency cepstrum (20 coefficients) - 140 features\n",
      "rmse: Root-mean-square - 7 features\n",
      "spectral_bandwidth: Spectral bandwidth - 7 features\n",
      "spectral_centroid: Spectral centroid - 7 features\n",
      "spectral_contrast: Spectral contrast (7 frequency bands) - 49 features\n",
      "spectral_rolloff: Roll-off frequency - 7 features\n",
      "tonnetz: Tonal centroid features (6 features) - 42 features\n",
      "zcr: Zero-crossing rate - 7 features\n",
      "x_train: 6000 rows on 518 columns\n",
      "Objects loaded: x_train, x_test, y_train as pd dataframes, x_train_np, x_test_np, y_train_np as NP arrays\n",
      "function generate_submission_csv(genre_predictions, filename='submission.csv') available\n"
     ]
    }
   ],
   "source": [
    "%run 'Setup.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Splitting, Scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/max/anaconda3/envs/sml-practical/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_np.ravel()) #\n",
    "\n",
    "# Split training data into training and temporary validation sets\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(x_train, y_train_encoded, test_size=0.4, random_state=42)\n",
    "\n",
    "# Split the temporary validation set into validation and test sets\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_real_test_scaled = scaler.transform(x_test_np)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Function Split Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def split_features_by_type(X, feature_structure):\n",
    "    \"\"\"\n",
    "    Splits the dataset into subsets based on the feature structure provided.\n",
    "\n",
    "    :param X: numpy array, the dataset to be split (features only)\n",
    "    :param feature_structure: dict, keys are feature names and values are the number of features of that type\n",
    "    :return: dict of feature subsets\n",
    "    \"\"\"\n",
    "    feature_subsets = {}\n",
    "    start_idx = 0\n",
    "\n",
    "    for feature_name, feature_count in feature_structure.items():\n",
    "        end_idx = start_idx + feature_count\n",
    "        feature_subsets[feature_name] = X[:, start_idx:end_idx]\n",
    "        start_idx = end_idx\n",
    "\n",
    "    return feature_subsets\n",
    "\n",
    "# Define the structure of your features based on the information you've provided\n",
    "feature_structure = {\n",
    "    'chroma_cens': 84,\n",
    "    'chroma_cqt': 84,\n",
    "    'chroma_stft': 84,\n",
    "    'mfcc': 140,\n",
    "    'rmse': 7,\n",
    "    'spectral_bandwidth': 7,\n",
    "    'spectral_centroid': 7,\n",
    "    'spectral_contrast': 49,\n",
    "    'spectral_rolloff': 7,\n",
    "    'tonnetz': 42,\n",
    "    'zcr': 7\n",
    "}\n",
    "\n",
    "# Example usage with a hypothetical dataset X_train_scaled\n",
    "# This would be your preprocessed and scaled training data as a NumPy array\n",
    "feature_subsets = split_features_by_type(X_train_scaled, feature_structure)\n",
    "\n",
    "# Now feature_subsets is a dictionary where, for example,\n",
    "# feature_subsets['mfcc'] contains only the MFCC features of the dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Subset Fits for Ensemble Learners"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Feature Subset Fit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming the preprocessing and data splitting is already done as per your provided code\n",
    "\n",
    "# Initialize a dictionary to store your best Random Forest models for each feature subset\n",
    "best_rf_models = {}\n",
    "\n",
    "# Train a Random Forest model for each feature subset\n",
    "for feature_name, X_train_subset in feature_subsets.items():\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train_subset, Y_train)\n",
    "    best_rf_models[feature_name] = rf_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy for chroma_cens features: 0.29\n",
      "Validation accuracy for chroma_cqt features: 0.33\n",
      "Validation accuracy for chroma_stft features: 0.3883333333333333\n",
      "Validation accuracy for mfcc features: 0.5133333333333333\n",
      "Validation accuracy for rmse features: 0.26666666666666666\n",
      "Validation accuracy for spectral_bandwidth features: 0.33166666666666667\n",
      "Validation accuracy for spectral_centroid features: 0.3525\n",
      "Validation accuracy for spectral_contrast features: 0.4608333333333333\n",
      "Validation accuracy for spectral_rolloff features: 0.3425\n",
      "Validation accuracy for tonnetz features: 0.2966666666666667\n",
      "Validation accuracy for zcr features: 0.3325\n",
      "Test accuracy with combined Random Forest models using weighted voting: 0.5408333333333334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate each model on the validation set and calculate weights\n",
    "weights = []\n",
    "val_feature_subsets = split_features_by_type(X_val_scaled, feature_structure)\n",
    "\n",
    "for feature_name, model in best_rf_models.items():\n",
    "    X_val_subset = val_feature_subsets[feature_name]\n",
    "    val_accuracy = model.score(X_val_subset, Y_val)\n",
    "    weights.append(val_accuracy)\n",
    "    print(f\"Validation accuracy for {feature_name} features: {val_accuracy}\")\n",
    "\n",
    "# Normalize weights\n",
    "weights = np.array(weights) / np.sum(weights)\n",
    "\n",
    "# Split the test set using the same feature structure and prepare for weighted predictions\n",
    "test_feature_subsets = split_features_by_type(X_test_scaled, feature_structure)\n",
    "weighted_test_predictions = np.zeros((X_test_scaled.shape[0], len(np.unique(Y_train))), dtype=float)\n",
    "\n",
    "for i, (feature_name, model) in enumerate(best_rf_models.items()):\n",
    "    X_test_subset = test_feature_subsets[feature_name]\n",
    "    predictions = model.predict_proba(X_test_subset)\n",
    "    weighted_predictions = predictions * weights[i]\n",
    "    weighted_test_predictions += weighted_predictions\n",
    "\n",
    "# Combine weighted predictions\n",
    "combined_test_predictions = np.argmax(weighted_test_predictions, axis=1)\n",
    "\n",
    "# Calculate and print test accuracy\n",
    "test_accuracy = np.mean(combined_test_predictions == Y_test)\n",
    "print(f\"Test accuracy with combined Random Forest models using weighted voting: {test_accuracy}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KNN Feature Subset Fit (from KNN.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K for chroma_cens features: 9 with cross-validation score: 0.2663888888888889\n",
      "Best K for chroma_cqt features: 13 with cross-validation score: 0.27361111111111114\n",
      "Best K for chroma_stft features: 13 with cross-validation score: 0.30194444444444446\n",
      "Best K for mfcc features: 15 with cross-validation score: 0.46611111111111103\n",
      "Best K for rmse features: 15 with cross-validation score: 0.23555555555555552\n",
      "Best K for spectral_bandwidth features: 15 with cross-validation score: 0.29083333333333333\n",
      "Best K for spectral_centroid features: 11 with cross-validation score: 0.32166666666666666\n",
      "Best K for spectral_contrast features: 12 with cross-validation score: 0.40861111111111115\n",
      "Best K for spectral_rolloff features: 12 with cross-validation score: 0.3061111111111111\n",
      "Best K for tonnetz features: 6 with cross-validation score: 0.2725000000000001\n",
      "Best K for zcr features: 14 with cross-validation score: 0.30583333333333335\n",
      "Validation accuracy with combined KNN models: 0.4725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Dictionary to store the trained KNN models for each feature subset\n",
    "knn_models = {}\n",
    "\n",
    "# Train a KNN model for each feature subset\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Dictionary to store the best KNN models for each feature subset\n",
    "best_knn_models = {}\n",
    "\n",
    "# Train a KNN model for each feature subset and find the best k using cross-validation\n",
    "for feature_name, X_subset in feature_subsets.items():\n",
    "    best_score = 0\n",
    "    best_k = 1\n",
    "    # Try different values of k\n",
    "    for k in range(1, 16):  # Let's try k from 1 to 15 as an example\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = cross_val_score(knn, X_subset, Y_train, cv=5)\n",
    "        mean_score = scores.mean()\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_k = k\n",
    "\n",
    "    # Train a new KNN model on the full training set with the best k\n",
    "    best_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    best_knn.fit(X_subset, Y_train)\n",
    "    best_knn_models[feature_name] = best_knn\n",
    "    print(f\"Best K for {feature_name} features: {best_k} with cross-validation score: {best_score}\")\n",
    "\n",
    "# Now best_knn_models dictionary contains the best KNN model for each feature subset\n",
    "\n",
    "\n",
    "# Now knn_models dictionary contains a trained KNN model for each feature subset\n",
    "# For example, knn_models['mfcc'] is the KNN model trained on the MFCC features\n",
    "\n",
    "# To make predictions, use the corresponding model for each feature subset\n",
    "# For instance, for MFCC features:\n",
    "# predictions_mfcc = knn_models['mfcc'].predict(feature_subsets['mfcc'])\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Assume we have a validation set X_val_scaled\n",
    "# Split it using the same function we defined earlier\n",
    "val_feature_subsets = split_features_by_type(X_val_scaled, feature_structure)\n",
    "\n",
    "# Gather predictions from all models on the validation set\n",
    "val_predictions = []\n",
    "for feature_name, model in best_knn_models.items():\n",
    "    # Ensure that we predict on the correct feature subset\n",
    "    X_val_subset = val_feature_subsets[feature_name]\n",
    "    predictions = model.predict(X_val_subset)\n",
    "    val_predictions.append(predictions)\n",
    "\n",
    "# Combine predictions using majority voting\n",
    "combined_val_predictions = mode(val_predictions, axis=0).mode\n",
    "\n",
    "# Calculate accuracy or any other metric based on the combined predictions\n",
    "val_accuracy = np.mean(combined_val_predictions.ravel() == Y_val)\n",
    "print(f\"Validation accuracy with combined KNN models: {val_accuracy}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression Feature Subset Fit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize a dictionary to store the logistic regression models for each feature subset\n",
    "best_lr_models = {}\n",
    "\n",
    "# Train a logistic regression model for each feature subset\n",
    "for feature_name, X_train_subset in feature_subsets.items():\n",
    "    lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    lr_model.fit(X_train_subset, Y_train)\n",
    "    best_lr_models[feature_name] = lr_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM Feature Subset Fit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize a dictionary to store the SVM models for each feature subset\n",
    "best_svm_models = {}\n",
    "\n",
    "# Train a polynomial kernel SVM model for each feature subset\n",
    "for feature_name, X_train_subset in feature_subsets.items():\n",
    "    # Specify the polynomial kernel using the `kernel` parameter\n",
    "    svm_model = SVC(probability=True, kernel='poly', degree=3, random_state=42)\n",
    "    svm_model.fit(X_train_subset, Y_train)\n",
    "    best_svm_models[feature_name] = svm_model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chroma_cens': SVC(probability=True, random_state=42), 'chroma_cqt': SVC(probability=True, random_state=42), 'chroma_stft': SVC(probability=True, random_state=42), 'mfcc': SVC(probability=True, random_state=42), 'rmse': SVC(probability=True, random_state=42), 'spectral_bandwidth': SVC(probability=True, random_state=42), 'spectral_centroid': SVC(probability=True, random_state=42), 'spectral_contrast': SVC(probability=True, random_state=42), 'spectral_rolloff': SVC(probability=True, random_state=42), 'tonnetz': SVC(probability=True, random_state=42), 'zcr': SVC(probability=True, random_state=42)}\n"
     ]
    }
   ],
   "source": [
    "print(best_svm_models)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy for chroma_cens features: 0.33\n",
      "Validation accuracy for chroma_cqt features: 0.35\n",
      "Validation accuracy for chroma_stft features: 0.38\n",
      "Validation accuracy for mfcc features: 0.56\n",
      "Validation accuracy for rmse features: 0.27\n",
      "Validation accuracy for spectral_bandwidth features: 0.33\n",
      "Validation accuracy for spectral_centroid features: 0.38\n",
      "Validation accuracy for spectral_contrast features: 0.47\n",
      "Validation accuracy for spectral_rolloff features: 0.37\n",
      "Validation accuracy for tonnetz features: 0.32\n",
      "Validation accuracy for zcr features: 0.34\n",
      "Test accuracy with combined SVM models using weighted voting: 0.57\n"
     ]
    }
   ],
   "source": [
    "# Calculate the validation accuracy for each feature subset and use it as weight for voting\n",
    "svm_weights = []\n",
    "for feature_name, model in best_svm_models.items():\n",
    "    X_val_subset = val_feature_subsets[feature_name]\n",
    "    val_accuracy = model.score(X_val_subset, Y_val)\n",
    "    svm_weights.append(val_accuracy)\n",
    "    print(f\"Validation accuracy for {feature_name} features: {val_accuracy:.2f}\")\n",
    "\n",
    "# Normalize weights so they sum up to 1\n",
    "svm_weights = np.array(svm_weights) / np.sum(svm_weights)\n",
    "\n",
    "# Predict on the test set with each SVM model and weight the predictions\n",
    "weighted_test_predictions_svm = np.zeros((X_test_scaled.shape[0], len(np.unique(Y_train))), dtype=float)  # Adjust the shape according to your number of classes\n",
    "\n",
    "for i, (feature_name, model) in enumerate(best_svm_models.items()):\n",
    "    X_test_subset = test_feature_subsets[feature_name]\n",
    "    predictions = model.predict_proba(X_test_subset)\n",
    "    weighted_predictions = predictions * svm_weights[i]\n",
    "    weighted_test_predictions_svm += weighted_predictions\n",
    "\n",
    "# Combine weighted predictions by taking the argmax to get final predictions\n",
    "combined_test_predictions_svm = np.argmax(weighted_test_predictions_svm, axis=1)\n",
    "\n",
    "# Calculate accuracy based on the combined weighted predictions\n",
    "test_accuracy_svm = np.mean(combined_test_predictions_svm == Y_test)\n",
    "print(f\"Test accuracy with combined SVM models using weighted voting: {test_accuracy_svm:.2f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost Feature Subset Fit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Initialize a dictionary to store the XGBoost models for each feature subset\n",
    "best_xgb_models = {}\n",
    "\n",
    "# Train an XGBoost model for each feature subset\n",
    "for feature_name, X_train_subset in feature_subsets.items():\n",
    "    xgb_model = xgb.XGBClassifier(use_label_encoder=False, objective='multi:softprob', num_class=8, eval_metric='mlogloss', random_state=42)\n",
    "    xgb_model.fit(X_train_subset, Y_train)\n",
    "    best_xgb_models[feature_name] = xgb_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stacked Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RF and KNN Stacked"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with stacked RF and KNN models: 0.5716666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data for the meta-model\n",
    "# Generate predictions from RF and KNN models on the validation set\n",
    "X_meta_train = np.hstack([\n",
    "    np.concatenate([\n",
    "        model.predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis]  # Add a new axis for stacking\n",
    "        for model in (best_rf_models[feature_name], best_knn_models[feature_name])\n",
    "    ], axis=2).mean(axis=2)  # Average predictions from RF and KNN models for each feature subset\n",
    "    for feature_name in feature_subsets.keys()\n",
    "]).reshape(len(Y_val), -1)  # Reshape to have a standard 2D array\n",
    "\n",
    "# Train the meta-model\n",
    "meta_model = LogisticRegression(random_state=42)\n",
    "meta_model.fit(X_meta_train, Y_val)\n",
    "\n",
    "# Prepare test data in a similar manner\n",
    "X_meta_test = np.hstack([\n",
    "    np.concatenate([\n",
    "        model.predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis]\n",
    "        for model in (best_rf_models[feature_name], best_knn_models[feature_name])\n",
    "    ], axis=2).mean(axis=2)\n",
    "    for feature_name in feature_subsets.keys()\n",
    "]).reshape(len(Y_test), -1)\n",
    "\n",
    "# Make final predictions with the meta-model\n",
    "final_predictions = meta_model.predict(X_meta_test)\n",
    "\n",
    "# Calculate and print the test accuracy\n",
    "test_accuracy = accuracy_score(Y_test, final_predictions)\n",
    "print(f\"Test accuracy with stacked RF and KNN models: {test_accuracy}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RF, KNN, and LR Stacked"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with stacked RF, KNN, and LR models: 0.5983333333333334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Update the preparation of the data for the meta-model to include logistic regression predictions\n",
    "X_meta_train = np.hstack([\n",
    "    np.concatenate([\n",
    "        best_rf_models[feature_name].predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_knn_models[feature_name].predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_lr_models[feature_name].predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis]\n",
    "    ], axis=2).mean(axis=2)  # Average predictions from RF, KNN, and LR models for each feature subset\n",
    "    for feature_name in feature_subsets.keys()\n",
    "]).reshape(len(Y_val), -1)  # Reshape to have a standard 2D array\n",
    "\n",
    "# Train the meta-model with the updated training data\n",
    "meta_model.fit(X_meta_train, Y_val)\n",
    "\n",
    "# Update the preparation of the test data in a similar manner to include logistic regression predictions\n",
    "X_meta_test = np.hstack([\n",
    "    np.concatenate([\n",
    "        best_rf_models[feature_name].predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_knn_models[feature_name].predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_lr_models[feature_name].predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis]\n",
    "    ], axis=2).mean(axis=2)\n",
    "    for feature_name in feature_subsets.keys()\n",
    "]).reshape(len(Y_test), -1)\n",
    "\n",
    "# Make final predictions with the updated meta-model\n",
    "final_predictions = meta_model.predict(X_meta_test)\n",
    "\n",
    "# Calculate and print the test accuracy with the inclusion of logistic regression models\n",
    "test_accuracy = accuracy_score(Y_test, final_predictions)\n",
    "print(f\"Test accuracy with stacked RF, KNN, and LR models: {test_accuracy}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best parameters for chroma_cens: {'C': 10, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best parameters for chroma_cqt: {'C': 10, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best parameters for chroma_stft: {'C': 10, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'kernel': ['poly'],  # Kernel type\n",
    "    'degree': [2, 3, 4],  # Degree of the polynomial kernel function\n",
    "    'gamma': ['scale', 'auto'],  # Kernel coefficient\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to store the best SVM models for each feature subset\n",
    "best_svm_models = {}\n",
    "\n",
    "# Perform grid search to find the best parameters for the SVM model for each feature subset\n",
    "for feature_name, X_train_subset in feature_subsets.items():\n",
    "    # Initialize the SVM model\n",
    "    svm = SVC(probability=True, random_state=42)\n",
    "\n",
    "    # Set up the grid search with cross-validation\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train_subset, Y_train)\n",
    "\n",
    "    # Retrieve the best model\n",
    "    best_svm_models[feature_name] = grid_search.best_estimator_\n",
    "\n",
    "    # Optionally, print the best parameters for each feature subset\n",
    "    print(f\"Best parameters for {feature_name}: {grid_search.best_params_}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RF, KNN, LR, and SVM models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with stacked RF, KNN, LR, and SVM models: 0.6125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Update the preparation of the data for the meta-model to include SVM predictions\n",
    "X_meta_train = np.hstack([\n",
    "    np.concatenate([\n",
    "        best_rf_models[feature_name].predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_knn_models[feature_name].predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_lr_models[feature_name].predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_svm_models[feature_name].predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis]  # Add SVM predictions\n",
    "    ], axis=2).mean(axis=2)  # Average predictions from RF, KNN, LR, and now SVM models for each feature subset\n",
    "    for feature_name in feature_subsets.keys()\n",
    "]).reshape(len(Y_val), -1)  # Reshape to have a standard 2D array\n",
    "\n",
    "# Re-train the meta-model with the updated training data including SVM predictions\n",
    "meta_model.fit(X_meta_train, Y_val)\n",
    "\n",
    "# Prepare the test data in a similar manner to include SVM predictions\n",
    "X_meta_test = np.hstack([\n",
    "    np.concatenate([\n",
    "        best_rf_models[feature_name].predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_knn_models[feature_name].predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_lr_models[feature_name].predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_svm_models[feature_name].predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis]  # Add SVM predictions\n",
    "    ], axis=2).mean(axis=2)\n",
    "    for feature_name in feature_subsets.keys()\n",
    "]).reshape(len(Y_test), -1)\n",
    "\n",
    "# Make final predictions with the updated meta-model including SVM\n",
    "final_predictions = meta_model.predict(X_meta_test)\n",
    "\n",
    "# Calculate and print the test accuracy with the inclusion of SVM models\n",
    "test_accuracy = accuracy_score(Y_test, final_predictions)\n",
    "print(f\"Test accuracy with stacked RF, KNN, LR, and SVM models: {test_accuracy}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RF, KNN, LR, SVM, and XGBoost models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with stacked RF, KNN, LR, SVM, and XGBoost models: 0.6166666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Update the preparation of the data for the meta-model to include XGBoost predictions\n",
    "X_meta_train = np.hstack([\n",
    "    np.concatenate([\n",
    "        best_rf_models[feature_name].predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_knn_models[feature_name].predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_lr_models[feature_name].predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_svm_models[feature_name].predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis],  # Existing SVM predictions\n",
    "        best_xgb_models[feature_name].predict_proba(val_feature_subsets[feature_name])[:, :, np.newaxis]  # Add XGBoost predictions\n",
    "    ], axis=2).mean(axis=2)  # Average predictions from all models for each feature subset\n",
    "    for feature_name in feature_subsets.keys()\n",
    "]).reshape(len(Y_val), -1)  # Reshape to have a standard 2D array\n",
    "\n",
    "# Re-train the meta-model with the updated training data including XGBoost predictions\n",
    "meta_model.fit(X_meta_train, Y_val)\n",
    "\n",
    "# Prepare the test data in a similar manner to include XGBoost predictions\n",
    "X_meta_test = np.hstack([\n",
    "    np.concatenate([\n",
    "        best_rf_models[feature_name].predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_knn_models[feature_name].predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_lr_models[feature_name].predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis],\n",
    "        best_svm_models[feature_name].predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis],  # Existing SVM predictions\n",
    "        best_xgb_models[feature_name].predict_proba(test_feature_subsets[feature_name])[:, :, np.newaxis]  # Add XGBoost predictions\n",
    "    ], axis=2).mean(axis=2)\n",
    "    for feature_name in feature_subsets.keys()\n",
    "]).reshape(len(Y_test), -1)\n",
    "\n",
    "# Make final predictions with the updated meta-model including XGBoost\n",
    "final_predictions = meta_model.predict(X_meta_test)\n",
    "\n",
    "# Calculate and print the test accuracy with the inclusion of XGBoost models\n",
    "test_accuracy = accuracy_score(Y_test, final_predictions)\n",
    "print(f\"Test accuracy with stacked RF, KNN, LR, SVM, and XGBoost models: {test_accuracy}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3600, 6000]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[43], line 27\u001B[0m\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m meta_features\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Assuming X_train, y_train are your full training set and labels\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Generate meta-features for the entire dataset\u001B[39;00m\n\u001B[0;32m---> 27\u001B[0m meta_features \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_meta_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mbest_rf_models\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mbest_knn_models\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mbest_lr_models\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mbest_svm_models\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_structure\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# Now you can use these meta-features to perform cross-validation on the meta-model\u001B[39;00m\n\u001B[1;32m     31\u001B[0m meta_model \u001B[38;5;241m=\u001B[39m LogisticRegression(random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n",
      "Cell \u001B[0;32mIn[43], line 10\u001B[0m, in \u001B[0;36mgenerate_meta_features\u001B[0;34m(model_dict, X, y, feature_structure)\u001B[0m\n\u001B[1;32m      7\u001B[0m meta_features \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;28mlen\u001B[39m(y), \u001B[38;5;28mlen\u001B[39m(model_dict)))  \u001B[38;5;66;03m# Placeholder for meta-features\u001B[39;00m\n\u001B[1;32m      8\u001B[0m kf \u001B[38;5;241m=\u001B[39m KFold(n_splits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m fold, (train_idx, test_idx) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(kf\u001B[38;5;241m.\u001B[39msplit(X, y)):\n\u001B[1;32m     11\u001B[0m     X_train, X_test \u001B[38;5;241m=\u001B[39m X[train_idx], X[test_idx]\n\u001B[1;32m     12\u001B[0m     y_train, _ \u001B[38;5;241m=\u001B[39m y[train_idx], y[test_idx]\n",
      "File \u001B[0;32m~/anaconda3/envs/sml-practical/lib/python3.10/site-packages/sklearn/model_selection/_split.py:342\u001B[0m, in \u001B[0;36m_BaseKFold.split\u001B[0;34m(self, X, y, groups)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msplit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, groups\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    319\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001B[39;00m\n\u001B[1;32m    320\u001B[0m \n\u001B[1;32m    321\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    340\u001B[0m \u001B[38;5;124;03m        The testing set indices for that split.\u001B[39;00m\n\u001B[1;32m    341\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 342\u001B[0m     X, y, groups \u001B[38;5;241m=\u001B[39m \u001B[43mindexable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    343\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(X)\n\u001B[1;32m    344\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_splits \u001B[38;5;241m>\u001B[39m n_samples:\n",
      "File \u001B[0;32m~/anaconda3/envs/sml-practical/lib/python3.10/site-packages/sklearn/utils/validation.py:443\u001B[0m, in \u001B[0;36mindexable\u001B[0;34m(*iterables)\u001B[0m\n\u001B[1;32m    424\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001B[39;00m\n\u001B[1;32m    425\u001B[0m \n\u001B[1;32m    426\u001B[0m \u001B[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    439\u001B[0m \u001B[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001B[39;00m\n\u001B[1;32m    440\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    442\u001B[0m result \u001B[38;5;241m=\u001B[39m [_make_indexable(X) \u001B[38;5;28;01mfor\u001B[39;00m X \u001B[38;5;129;01min\u001B[39;00m iterables]\n\u001B[0;32m--> 443\u001B[0m \u001B[43mcheck_consistent_length\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    444\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/anaconda3/envs/sml-practical/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[0;34m(*arrays)\u001B[0m\n\u001B[1;32m    395\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[1;32m    396\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 397\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    398\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    399\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[1;32m    400\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [3600, 6000]"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Stacked Bootstrap"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with bootstrapped and stacked RF, KNN, and LR models: 0.5933333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Define the number of bootstrap samples and models\n",
    "n_bootstrap_samples = 10\n",
    "\n",
    "# Placeholder for trained bootstrap models\n",
    "bootstrap_models_rf = {feature_name: [] for feature_name in feature_subsets.keys()}\n",
    "bootstrap_models_knn = {feature_name: [] for feature_name in feature_subsets.keys()}\n",
    "bootstrap_models_lr = {feature_name: [] for feature_name in feature_subsets.keys()}\n",
    "\n",
    "# Train bootstrap models for RandomForest\n",
    "for feature_name, X_train_subset in feature_subsets.items():\n",
    "    for _ in range(n_bootstrap_samples):\n",
    "        # Create a bootstrap sample\n",
    "        X_boot, Y_boot = resample(X_train_subset, Y_train)\n",
    "        # Initialize and train the model on the bootstrap sample\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "        model.fit(X_boot, Y_boot)\n",
    "        bootstrap_models_rf[feature_name].append(model)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# Train bootstrap models for KNN\n",
    "for feature_name, X_train_subset in feature_subsets.items():\n",
    "    for _ in range(n_bootstrap_samples):\n",
    "        X_boot, Y_boot = resample(X_train_subset, Y_train)\n",
    "        knn_model = KNeighborsClassifier()\n",
    "        knn_model.fit(X_boot, Y_boot)\n",
    "        bootstrap_models_knn[feature_name].append(knn_model)\n",
    "\n",
    "# Train bootstrap models for Logistic Regression\n",
    "for feature_name, X_train_subset in feature_subsets.items():\n",
    "    for _ in range(n_bootstrap_samples):\n",
    "        X_boot, Y_boot = resample(X_train_subset, Y_train)\n",
    "        lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "        lr_model.fit(X_boot, Y_boot)\n",
    "        bootstrap_models_lr[feature_name].append(lr_model)\n",
    "\n",
    "# Generate averaged predictions for the validation set\n",
    "# This assumes `val_feature_subsets` is already prepared similarly to `feature_subsets`\n",
    "X_meta_train = np.hstack([\n",
    "    np.mean([\n",
    "        np.mean([model.predict_proba(val_feature_subsets[feature_name]) for model in models], axis=0)\n",
    "        for models in (bootstrap_models_rf[feature_name], bootstrap_models_knn[feature_name], bootstrap_models_lr[feature_name])\n",
    "    ], axis=0)\n",
    "    for feature_name in feature_subsets.keys()\n",
    "]).reshape(len(Y_val), -1)\n",
    "\n",
    "# Train the meta-model\n",
    "meta_model.fit(X_meta_train, Y_val)\n",
    "\n",
    "# Assuming `test_feature_subsets` is prepared, generate predictions for the test set\n",
    "X_meta_test = np.hstack([\n",
    "    np.mean([\n",
    "        np.mean([model.predict_proba(test_feature_subsets[feature_name]) for model in models], axis=0)\n",
    "        for models in (bootstrap_models_rf[feature_name], bootstrap_models_knn[feature_name], bootstrap_models_lr[feature_name])\n",
    "    ], axis=0)\n",
    "    for feature_name in feature_subsets.keys()\n",
    "]).reshape(len(Y_test), -1)\n",
    "\n",
    "# Final predictions with the meta-model\n",
    "final_predictions = meta_model.predict(X_meta_test)\n",
    "\n",
    "# Calculate and print the test accuracy\n",
    "test_accuracy = accuracy_score(Y_test, final_predictions)\n",
    "print(f\"Test accuracy with bootstrapped and stacked RF, KNN, and LR models: {test_accuracy}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Best Model per Feature Subset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with the best model from each feature subset ensemble: 0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `feature_subsets`, `X_val_scaled`, and `Y_val` are already defined\n",
    "\n",
    "# Step 1: Train models on each feature subset\n",
    "model_types = ['KNN', 'RF', 'LR', 'SVM']\n",
    "best_models = {}\n",
    "\n",
    "for feature_name, X_train_subset in feature_subsets.items():\n",
    "    # Track the best model for this subset\n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    X_val_subset = val_feature_subsets[feature_name]\n",
    "\n",
    "    # KNN Model\n",
    "    knn_model = KNeighborsClassifier()\n",
    "    knn_model.fit(X_train_subset, Y_train)\n",
    "    knn_accuracy = knn_model.score(X_val_subset, Y_val)\n",
    "\n",
    "    if knn_accuracy > best_accuracy:\n",
    "        best_accuracy = knn_accuracy\n",
    "        best_model = ('KNN', knn_model)\n",
    "\n",
    "    # RF Model\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train_subset, Y_train)\n",
    "    rf_accuracy = rf_model.score(X_val_subset, Y_val)\n",
    "\n",
    "    if rf_accuracy > best_accuracy:\n",
    "        best_accuracy = rf_accuracy\n",
    "        best_model = ('RF', rf_model)\n",
    "\n",
    "    # LR Model\n",
    "    lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    lr_model.fit(X_train_subset, Y_train)\n",
    "    lr_accuracy = lr_model.score(X_val_subset, Y_val)\n",
    "\n",
    "    if lr_accuracy > best_accuracy:\n",
    "        best_accuracy = lr_accuracy\n",
    "        best_model = ('LR', lr_model)\n",
    "\n",
    "    # LR Model\n",
    "    lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    lr_model.fit(X_train_subset, Y_train)\n",
    "    lr_accuracy = lr_model.score(X_val_subset, Y_val)\n",
    "\n",
    "    if lr_accuracy > best_accuracy:\n",
    "        best_accuracy = lr_accuracy\n",
    "        best_model = ('LR', lr_model)\n",
    "\n",
    "    best_models[feature_name] = best_model\n",
    "\n",
    "# Step 2: Evaluate and select the best model per subset (already done in the loop)\n",
    "\n",
    "# Step 3: Ensemble selected models for final prediction\n",
    "# Generate predictions for each selected model on the test set\n",
    "ensemble_predictions = np.zeros((len(Y_test), len(np.unique(Y_train))))\n",
    "\n",
    "for feature_name, (model_type, model) in best_models.items():\n",
    "    X_test_subset = test_feature_subsets[feature_name]\n",
    "    predictions = model.predict_proba(X_test_subset)\n",
    "    ensemble_predictions += predictions\n",
    "\n",
    "# Final ensemble prediction\n",
    "final_predictions = np.argmax(ensemble_predictions, axis=1)\n",
    "\n",
    "# Calculate and print the test accuracy\n",
    "test_accuracy = accuracy_score(Y_test, final_predictions)\n",
    "print(f\"Test accuracy with the best model from each feature subset ensemble: {test_accuracy}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with weighted averaging ensemble: 0.5408333333333334\n"
     ]
    }
   ],
   "source": [
    "# Assuming `best_models` and their validation accuracies are already calculated\n",
    "\n",
    "# Placeholder for models, their weights, and validation feature subsets\n",
    "selected_models = []\n",
    "model_weights = []\n",
    "val_feature_subsets = split_features_by_type(X_val_scaled, feature_structure)  # Ensure this is defined\n",
    "\n",
    "# Calculate the validation accuracy for each selected model and use it as the weight\n",
    "for feature_name, (model_type, model) in best_models.items():\n",
    "    X_val_subset = val_feature_subsets[feature_name]\n",
    "    val_accuracy = model.score(X_val_subset, Y_val)\n",
    "    selected_models.append(model)\n",
    "    model_weights.append(val_accuracy)\n",
    "\n",
    "# Normalize the weights so they sum up to 1\n",
    "total_weight = sum(model_weights)\n",
    "normalized_weights = [weight / total_weight for weight in model_weights]\n",
    "\n",
    "# Apply weighted averaging for the final ensemble predictions\n",
    "weighted_ensemble_predictions = np.zeros((len(Y_test), len(np.unique(Y_train))))\n",
    "\n",
    "for model, weight, feature_name in zip(selected_models, normalized_weights, best_models.keys()):\n",
    "    X_test_subset = test_feature_subsets[feature_name]\n",
    "    prob_predictions = model.predict_proba(X_test_subset)\n",
    "    weighted_ensemble_predictions += prob_predictions * weight\n",
    "\n",
    "# The final prediction is the class with the highest weighted sum across all models\n",
    "final_predictions_weighted = np.argmax(weighted_ensemble_predictions, axis=1)\n",
    "\n",
    "# Calculate and print the test accuracy with weighted averaging\n",
    "test_accuracy_weighted = accuracy_score(Y_test, final_predictions_weighted)\n",
    "print(f\"Test accuracy with weighted averaging ensemble: {test_accuracy_weighted}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 13\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Existing model training and evaluation for KNN, RF, LR...\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# SVM Model\u001B[39;00m\n\u001B[1;32m     12\u001B[0m svm_model \u001B[38;5;241m=\u001B[39m SVC(probability\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m---> 13\u001B[0m \u001B[43msvm_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_subset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m svm_accuracy \u001B[38;5;241m=\u001B[39m svm_model\u001B[38;5;241m.\u001B[39mscore(X_val_subset, Y_val)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m svm_accuracy \u001B[38;5;241m>\u001B[39m best_accuracy:\n",
      "File \u001B[0;32m~/anaconda3/envs/sml-practical/lib/python3.10/site-packages/sklearn/svm/_base.py:252\u001B[0m, in \u001B[0;36mBaseLibSVM.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    249\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LibSVM]\u001B[39m\u001B[38;5;124m\"\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    251\u001B[0m seed \u001B[38;5;241m=\u001B[39m rnd\u001B[38;5;241m.\u001B[39mrandint(np\u001B[38;5;241m.\u001B[39miinfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mi\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mmax)\n\u001B[0;32m--> 252\u001B[0m \u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msolver_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001B[39;00m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape_fit_ \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(X, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m (n_samples,)\n",
      "File \u001B[0;32m~/anaconda3/envs/sml-practical/lib/python3.10/site-packages/sklearn/svm/_base.py:331\u001B[0m, in \u001B[0;36mBaseLibSVM._dense_fit\u001B[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001B[0m\n\u001B[1;32m    317\u001B[0m libsvm\u001B[38;5;241m.\u001B[39mset_verbosity_wrap(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[1;32m    319\u001B[0m \u001B[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001B[39;00m\n\u001B[1;32m    320\u001B[0m \u001B[38;5;66;03m# add other parameters to __init__\u001B[39;00m\n\u001B[1;32m    321\u001B[0m (\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupport_,\n\u001B[1;32m    323\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupport_vectors_,\n\u001B[1;32m    324\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_support,\n\u001B[1;32m    325\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdual_coef_,\n\u001B[1;32m    326\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept_,\n\u001B[1;32m    327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_probA,\n\u001B[1;32m    328\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_probB,\n\u001B[1;32m    329\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_status_,\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_iter,\n\u001B[0;32m--> 331\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[43mlibsvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    332\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    333\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    334\u001B[0m \u001B[43m    \u001B[49m\u001B[43msvm_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    335\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    336\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001B[39;49;00m\n\u001B[1;32m    337\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m_class_weight\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    338\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkernel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    339\u001B[0m \u001B[43m    \u001B[49m\u001B[43mC\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mC\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    340\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnu\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    341\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprobability\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprobability\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    342\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdegree\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdegree\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    343\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshrinking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshrinking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    345\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcoef0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoef0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgamma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gamma\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepsilon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepsilon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_seed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_warn_from_fit_status()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
